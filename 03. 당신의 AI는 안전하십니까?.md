## 조직에서 AI를 활용하는 2가지 방법

- 직접 모델을 만든다
- GPT와 같은 누군가가 만든 모델을 응용하는 방법

### MLOps 는 기본적으로 블랙박스다.

1. 모델을 디자인 하는 단계
2. 모델을 개발하는 단계
   - 알고리즘 식별, 선정 등
3. 운영 단계

### CI, CD, CT, CM

- CT : Continuous Traning
  - 모델은 살아있는 객체
- CM : Continuous Monitoring
  - 지속적인 관찰

만드는 모델에는 CT와 CM이 반드시 필요하다.

### 모델에 대해서도 버전이 반드시 필요하다.

- 모델의 배포기능

---

- MLflow
  - 내장형 파이프라인 오케스트레이션 기능 부족
- Hubeflow
  - k8s 기반
- TensorFlow Extended
  -

조직내의 인프라에 따라 프레임워크를 선택해라

---

# AI에 대한 공격이 곧 시작될 것이다.

## 데이터 수집 단계에서 문제

- 데이터의 라이센스, 액세스 여부 , 파이프 라인의 프로세스가 존재하는지
- 저장공간에 대한 액세스 권한'
- 안정성 확보
- 파이프라인 구축

## 모델을 생성하는 단계

- 모델을 사용하는 라이브러리가 얼마나 신뢰할 수 있는지
- 출처를 확인하는 것이 굉장히 중요하다.

## 모델 발전, 선택과정

- 모델이 이상한 행동을 한다거나
- 예상치 않은 질문에 어떻게 대응하는지
- 지속적으로 모니터링 해줘야 문제없게 만들 수 있다.

---

# 모델 회피 기능

- 사람에게 그림이 들어가면 인식을 못하게 하는 회피 공격이 가능하다.

- 모델 자체를 도난하는 방법도 있다.

  - 쿼리 입력값을 제한함으로써 방어할 수 있다.
  - 빅 쿼리를 통해서 훔쳐가기 때문에

- 훈련데이터 유출
- 실제 정교한 입력값을 이용해서 데이터가 유출될 수 있다.

### 코드 삽입

- 악성 코드를 데이터에 들어가있는 형태로 모델에 넣는다
  - 모델 결과값으로 나쁜 행동을 하게 만들 수 있다.
- 악성 모델을 다운받게 만들어서 보안을 위협할 수도 있다. (모델 허브에서)

---

## 모델 모니터링

- 문제가 발생했을 때 빠르게 캐치할 수 있느냐
  - 문제가 발생했을 때 백업 등을 이용해 대처를 할 수 있느냐

## 생성형 AI 보안 취약점

### req, res cycle

- api 단계
  - 프롬프트 인잭션
  - 인시큐어 아웃풋 핸들링
  - 여러 취약점이 발생할 수 있음.
    - 소스코드 자체에서 문제가 발생하지 않게 만들어야한다.
- 모델 단계
  - 도메인 전문가와 AI 분야 전문가가 데이터가 어떻게 유출될 수 있는지 확인해야한다.
- Retrieval 보안
  - 개인 정보에 대한 데이터
  - 보안적으로 좋지 않은 데이터를 출력하지는 않을지

### AI모델을 선택 할 때 보안 문제는 해결해야한다.

- 아키텍처를 잘 제공할 수 있는 파트너인가, 보안적으로 안전한가 확인을 반드시 해야한다.

- 결국 공격은 반드시 일어난다.
